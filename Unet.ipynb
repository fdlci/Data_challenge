{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Essentials\n",
    "import time\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import os\n",
    "from tifffile import TiffFile\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "# Torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "# segmentation_models_pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "# Albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# Local \n",
    "from unet import UNet\n",
    "from LCD import LandCoverData\n",
    "from dataset import *\n",
    "from train import *\n",
    "from utils import *\n",
    "from metrics import *\n",
    "from losses import *\n",
    "LCD = LandCoverData()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏èSeed everything!\n",
    "It's important to seed everything for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìú Set all variables here\n",
    "In this cell, we define all hyperparameters that we will be using for the rest of the notebook. It helps to group them in one place so we can track them better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'resnet18'\n",
    "OPTIMIZER = 'adam'\n",
    "NB_EPOCHS = 20\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 8\n",
    "IN_CHANNELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet18_20_epochs_0.01_learningrate_8_batchsize_seed_2021'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{MODEL}_{NB_EPOCHS}_epochs_{LEARNING_RATE}_learningrate_{BATCH_SIZE}_batchsize_seed_{seed}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.ToFloat(max_value=65535.0),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=5, p=0.5),\n",
    "    A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "    A.FromFloat(max_value=65535.0),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(1, 1, 1, 1), max_pixel_value=65535),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(1, 1, 1, 1), max_pixel_value=65535),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate datasets\n",
    "Here we perform a train/validation split in otder to evaluate our model. We then feed them to the ImageSegementationDataset so to make the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set contains 14792 elements\n",
      "Validation set contains 3699 elements\n",
      "Test set contains 5043 elements\n"
     ]
    }
   ],
   "source": [
    "train_dir='dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "train_idx, val_idx = train_val_dataset(train_dir, val_split=0.2)\n",
    "train_set = ImageSegementationDataset(train_dir, in_channels=IN_CHANNELS, path_index=train_idx, mode='train', transforms=train_transform)\n",
    "val_set = ImageSegementationDataset(train_dir, in_channels=IN_CHANNELS, path_index=val_idx, mode='valid', transforms=test_transform)\n",
    "test_set = ImageSegementationDataset(test_dir, in_channels=IN_CHANNELS, mode='test', transforms=test_transform)\n",
    "\n",
    "print(\"Train set contains\", len(train_set), \"elements\")\n",
    "print(\"Validation set contains\", len(val_set), \"elements\")\n",
    "print(\"Test set contains\", len(test_set), \"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1849 batches in the training set\n",
      "There are 463 batches in the validation set\n"
     ]
    }
   ],
   "source": [
    "loader_train = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_valid = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_test = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "data_sizes = {\"train\": len(loader_train), \"valid\": len(loader_valid)}\n",
    "print(\"There are\", data_sizes['train'], \"batches in the training set\")\n",
    "print(\"There are\", data_sizes['valid'], \"batches in the validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by initializing our model along with the loss and optimizers and feed that to the Trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(encoder_name='resnet18',in_channels=IN_CHANNELS, classes=10, encoder_weights=None, activation=None)\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "criterion = CombinedLoss()\n",
    "loaders = {\n",
    "    \"train\": loader_train,\n",
    "    \"val\": loader_valid\n",
    "}\n",
    "trainer = Trainer(model, loaders, optimizer_ft, criterion, scheduler, device)\n",
    "trainer.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e3776706494440bdd684475b9921cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JaggBow\\Desktop\\Graduate studies\\MVA\\RP\\Data_challenge\\losses.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encoded_target.scatter_(1, torch.tensor(y_true.unsqueeze(1), dtype=torch.int64), 1.)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f49a0980a154eb1b5fa9699d0212c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0 Training Loss: 0.9259679610500986 Training IoU: 0.3644735773917066 Training KL: 0.3375816458114035\n",
      "Epoch # 0 Validation Loss: 0.9352664579325567 Validation IoU: 0.36304874948483723 Validation KL: 0.5576068113176201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85bfe4c85bc40f7addcaf1b8e2e4121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372e6f627ca6491b9c85bc14e8d03d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1 Training Loss: 0.8497689200969178 Training IoU: 0.4450224161895631 Training KL: 0.1458603977352331\n",
      "Epoch # 1 Validation Loss: 0.9070754482473204 Validation IoU: 0.40295520579957256 Validation KL: 0.3432704763975755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f3f52ba71b4fd888e4430bcc20bd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63b7a5f70464349b5df1aa001356e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.run(NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_distribution(y):\n",
    "    class_distribution = np.apply_along_axis(np.bincount, axis=1, arr=y.flatten(1), minlength=LCD.N_CLASSES)\n",
    "    # Normalize to sum to 1  \n",
    "    return (class_distribution.T/class_distribution.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83da850d3e46475f94aa6e92ff802d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_dict = {\"sample_id\":[], \"no_data\":[],\"clouds\":[],\"artificial\":[],\"cultivated\":[],\"broadleaf\":[],\"coniferous\":[],\"herbaceous\":[],\"natural\":[],\"snow\":[],\"water\":[]}\n",
    "for image, path in tqdm(loader_test):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = unet_pre_trained(image)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        class_dis = batch_distribution(preds.cpu())\n",
    "        sub_dict[\"sample_id\"] += [int(p.split('.')[0]) for p in path]\n",
    "        for key in LCD.CLASSES:\n",
    "            sub_dict[key] += class_dis[:,LCD.CLASSES.index(key)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>no_data</th>\n",
       "      <th>clouds</th>\n",
       "      <th>artificial</th>\n",
       "      <th>cultivated</th>\n",
       "      <th>broadleaf</th>\n",
       "      <th>coniferous</th>\n",
       "      <th>herbaceous</th>\n",
       "      <th>natural</th>\n",
       "      <th>snow</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>10087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.248520</td>\n",
       "      <td>0.196350</td>\n",
       "      <td>0.013412</td>\n",
       "      <td>0.528641</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>10088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.410492</td>\n",
       "      <td>0.176392</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.405426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>10089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055969</td>\n",
       "      <td>0.259369</td>\n",
       "      <td>0.226807</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>0.426941</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>10090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.037643</td>\n",
       "      <td>0.517822</td>\n",
       "      <td>0.148590</td>\n",
       "      <td>0.285034</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>10091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026031</td>\n",
       "      <td>0.363190</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>0.397568</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id  no_data  clouds  artificial  cultivated  broadleaf  \\\n",
       "3436      10087      0.0     0.0    0.007431    0.248520   0.196350   \n",
       "3073      10088      0.0     0.0    0.004990    0.410492   0.176392   \n",
       "497       10089      0.0     0.0    0.055969    0.259369   0.226807   \n",
       "1319      10090      0.0     0.0    0.009201    0.037643   0.517822   \n",
       "2484      10091      0.0     0.0    0.026031    0.363190   0.188400   \n",
       "\n",
       "      coniferous  herbaceous   natural  snow     water  \n",
       "3436    0.013412    0.528641  0.000122   0.0  0.005524  \n",
       "3073    0.002701    0.405426  0.000000   0.0  0.000000  \n",
       "497     0.024384    0.426941  0.000015   0.0  0.006516  \n",
       "1319    0.148590    0.285034  0.001709   0.0  0.000000  \n",
       "2484    0.024353    0.397568  0.000229   0.0  0.000229  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.DataFrame.from_dict(sub_dict)\n",
    "df_sub = df_sub.sort_values(by='sample_id')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(),\"unet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_saved_model(model_name):\n",
    "    \"\"\"Loads the saved model\"\"\"\n",
    "    model = unet\n",
    "    model.load_state_dict(torch.load(model_name, map_location = device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model_loaded = loading_saved_model(\"unet.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2s",
   "language": "python",
   "name": "l2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
