{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Essentials\n",
    "import time\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import os\n",
    "from tifffile import TiffFile\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "# Torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "# segmentation_models_pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "# Albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# Local \n",
    "from unet import UNet\n",
    "from LCD import LandCoverData\n",
    "from dataset import *\n",
    "from train import *\n",
    "from utils import *\n",
    "from metrics import *\n",
    "from losses import *\n",
    "LCD = LandCoverData()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏èSeed everything!\n",
    "It's important to seed everything for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìú Set all variables here\n",
    "In this cell, we define all hyperparameters that we will be using for the rest of the notebook. It helps to group them in one place so we can track them better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'resnet18'\n",
    "OPTIMIZER = 'adam'\n",
    "NB_EPOCHS = 20\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 8\n",
    "IN_CHANNELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet18_20_epochs_0.01_learningrate_8_batchsize_seed_2021'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{MODEL}_{NB_EPOCHS}_epochs_{LEARNING_RATE}_learningrate_{BATCH_SIZE}_batchsize_seed_{seed}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.ToFloat(max_value=65535.0),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=5, p=0.5),\n",
    "    A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "    A.FromFloat(max_value=65535.0),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(1, 1, 1, 1), max_pixel_value=65535),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(1, 1, 1, 1), max_pixel_value=65535),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate datasets\n",
    "Here we perform a train/validation split in otder to evaluate our model. We then feed them to the ImageSegementationDataset so to make the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set contains 14792 elements\n",
      "Validation set contains 3699 elements\n",
      "Test set contains 5043 elements\n"
     ]
    }
   ],
   "source": [
    "train_idx, val_idx = train_val_dataset(train_dir, val_split=0.2)\n",
    "train_set = ImageSegementationDataset(train_dir, in_channels=IN_CHANNELS, path_index=train_idx, mode='train', transforms=train_transform)\n",
    "val_set = ImageSegementationDataset(train_dir, in_channels=IN_CHANNELS, path_index=val_idx, mode='valid', transforms=test_transform)\n",
    "test_set = ImageSegementationDataset(test_dir, in_channels=IN_CHANNELS, mode='test', transforms=test_transform)\n",
    "\n",
    "print(\"Train set contains\", len(train_set), \"elements\")\n",
    "print(\"Validation set contains\", len(val_set), \"elements\")\n",
    "print(\"Test set contains\", len(test_set), \"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1849 batches in the training set\n",
      "There are 463 batches in the validation set\n"
     ]
    }
   ],
   "source": [
    "loader_train = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_valid = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_test = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "data_sizes = {\"train\": len(loader_train), \"valid\": len(loader_valid)}\n",
    "print(\"There are\", data_sizes['train'], \"batches in the training set\")\n",
    "print(\"There are\", data_sizes['valid'], \"batches in the validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = (y_pred_f * y_true_f).sum()\n",
    "    smooth = 0.0001\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "def change_shape(y_true, y_pred, numLabels):  \n",
    "\n",
    "    encoded_target = y_pred.data.clone().zero_()\n",
    "    encoded_target[...] = 0\n",
    "    encoded_target.scatter_(1, torch.tensor(y_true.unsqueeze(1), dtype=torch.int64), 1.)\n",
    "    encoded_target = Variable(encoded_target)\n",
    "    return encoded_target\n",
    "\n",
    "def dice_coef_multilabel(y_pred, y_true, numLabels):\n",
    "    dice=0\n",
    "    y_true = change_shape(y_true, y_pred, numLabels)\n",
    "    for index in range(numLabels):\n",
    "        dice += dice_coef(y_true[:,index,:,:], y_pred[:,index,:,:])\n",
    "    return dice/numLabels # taking average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIOU(label, pred, num_classes=10):\n",
    "    iou_list = list()\n",
    "    present_iou_list = list()\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    # Note: Following for loop goes from 0 to (num_classes-1)\n",
    "    # and ignore_index is num_classes, thus ignore_index is\n",
    "    # not considered in computation of IoU.\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = (pred == sem_class)\n",
    "        target_inds = (label == sem_class)\n",
    "        if target_inds.long().sum().item() == 0:\n",
    "            iou_now = float('nan')\n",
    "        else: \n",
    "            intersection_now = (pred_inds[target_inds]).long().sum().item()\n",
    "            union_now = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection_now\n",
    "            iou_now = float(intersection_now) / float(union_now)\n",
    "            present_iou_list.append(iou_now)\n",
    "        iou_list.append(iou_now)\n",
    "    return np.mean(present_iou_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_kl_divergence(y_true, y_pred):\n",
    "    class_distribution_true = np.apply_along_axis(np.bincount, axis=1, arr=y_true.flatten(1), minlength=LCD.N_CLASSES)\n",
    "    class_distribution_pred = np.apply_along_axis(np.bincount, axis=1, arr=y_pred.flatten(1), minlength=LCD.N_CLASSES)\n",
    "    # Normalize to sum to 1  \n",
    "    normalized_class_distribution_true = (class_distribution_true.T/class_distribution_true.sum(1)).T\n",
    "    normalized_class_distribution_pred = (class_distribution_pred.T/class_distribution_pred.sum(1)).T\n",
    "    # add a small constant for smoothness around 0\n",
    "    normalized_class_distribution_true += 1e-7\n",
    "    normalized_class_distribution_pred += 1e-7\n",
    "\n",
    "    score = np.mean(np.sum(normalized_class_distribution_true * np.log(normalized_class_distribution_true / normalized_class_distribution_pred), 1))\n",
    "    try:\n",
    "        assert np.isfinite(score)\n",
    "    except AssertionError as e:\n",
    "        raise ValueError('score is NaN or infinite') from e\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, valid_loader, data_sizes, epochs, optimizer, scheduler, title):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device\", device)\n",
    "    model.to(device)\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    num_workers = 1\n",
    "\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 1000\n",
    "\n",
    "    loaders = {\"train\": train_loader, \"valid\": valid_loader}\n",
    "    step = 0\n",
    "\n",
    "    class_weights = class_weight().to(device)\n",
    "    criterion_1 = nn.CrossEntropyLoss(class_weights)\n",
    "    criterion_2 = dice_coef_multilabel\n",
    "    criterion_3 = nn.BCELoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_iou = 0\n",
    "            running_kl_div = 0\n",
    "\n",
    "            for image, mask in tqdm(loaders[phase]):\n",
    "                image = image.to(device)\n",
    "                mask = mask.to(device)\n",
    "                \n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "\n",
    "                    output = model(image)\n",
    "                    _, preds = torch.max(output, 1)\n",
    "\n",
    "                    #loss = criterion(output, torch.tensor(mask, dtype=torch.long, device=device).squeeze())\n",
    "                    #loss = 0.5*criterion_1(output, torch.tensor(mask, dtype=torch.long, device=device).squeeze())+criterion_2(output, mask.squeeze(), LCD.N_CLASSES)\n",
    "                    true = change_shape(mask.squeeze(), output, 10)\n",
    "                    loss = criterion_3(output, true)+1-criterion_2(output, mask.squeeze(), LCD.N_CLASSES)\n",
    "\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_iou += mIOU(mask, preds)\n",
    "                running_kl_div += epsilon_kl_divergence(mask.cpu(), preds.cpu())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss/data_sizes[phase]\n",
    "            epoch_iou = running_iou/data_sizes[phase]\n",
    "            epoch_kl = running_kl_div/data_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                training_loss.append(epoch_loss)\n",
    "            else:\n",
    "                validation_loss.append(epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:.4f} IoU: {:.4f} KL_div: {:.4f}'.format(phase, epoch_loss, epoch_iou, epoch_kl))\n",
    "            \n",
    "            if phase == 'valid' and epoch_kl < best_acc:\n",
    "                best_acc = epoch_kl\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(),\"unet_timm-efficientnet-b3_3_channels.pt\")\n",
    "\n",
    "            \n",
    "    # Plotting the validation loss and training loss\n",
    "    print('validation loss: ' + str(validation_loss))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # plot the training and validation loss\n",
    "    plt.figure()\n",
    "    plt.plot(training_loss, 'b', label='Training Loss')\n",
    "    plt.plot(validation_loss, 'r', label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show() #Change title for every model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_dir, model, epochs, learning_rate):\n",
    "    # Optimizing all parameters\n",
    "    optimizer_ft = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "    # Training the model\n",
    "    title = 'Variations of the training and validation loss SGD'\n",
    "    model_ft = training(model, loader_train, loader_valid, data_sizes, epochs, optimizer_ft, exp_lr_scheduler, title)\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_pre_trained = smp.Unet(encoder_name='resnet18',in_channels=IN_CHANNELS, classes=10, encoder_weights=None, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda:0\n",
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9ab088e77c4d7a8856490172f9cb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-139ed2cd8cf9>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encoded_target.scatter_(1, torch.tensor(y_true.unsqueeze(1), dtype=torch.int64), 1.)\n"
     ]
    }
   ],
   "source": [
    "unet_pre_trained = train_model('dataset/train', unet_pre_trained, epochs=NB_EPOCHS, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94bde4829634bc9bcba726bd4781f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "running_iou = 0\n",
    "running_kl_div = 0\n",
    "unet_pre_trained.eval()\n",
    "for image, mask in tqdm(loader_valid):\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = unet_pre_trained(image)\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        running_iou += mIOU(mask, preds)\n",
    "        running_kl_div += epsilon_kl_divergence(mask.cpu(), preds.cpu())\n",
    "\n",
    "\n",
    "epoch_iou = running_iou/len(loader_valid)\n",
    "epoch_kl = running_kl_div/len(loader_valid)\n",
    "\n",
    "print('Validation IoU', epoch_iou, \"Validation KL divergence\", epoch_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(unet_pre_trained.state_dict(),\"unet_timm-efficientnet-b3_62_epochs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_distribution(y):\n",
    "    class_distribution = np.apply_along_axis(np.bincount, axis=1, arr=y.flatten(1), minlength=LCD.N_CLASSES)\n",
    "    # Normalize to sum to 1  \n",
    "    return (class_distribution.T/class_distribution.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83da850d3e46475f94aa6e92ff802d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_dict = {\"sample_id\":[], \"no_data\":[],\"clouds\":[],\"artificial\":[],\"cultivated\":[],\"broadleaf\":[],\"coniferous\":[],\"herbaceous\":[],\"natural\":[],\"snow\":[],\"water\":[]}\n",
    "for image, path in tqdm(loader_test):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = unet_pre_trained(image)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        class_dis = batch_distribution(preds.cpu())\n",
    "        sub_dict[\"sample_id\"] += [int(p.split('.')[0]) for p in path]\n",
    "        for key in LCD.CLASSES:\n",
    "            sub_dict[key] += class_dis[:,LCD.CLASSES.index(key)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>no_data</th>\n",
       "      <th>clouds</th>\n",
       "      <th>artificial</th>\n",
       "      <th>cultivated</th>\n",
       "      <th>broadleaf</th>\n",
       "      <th>coniferous</th>\n",
       "      <th>herbaceous</th>\n",
       "      <th>natural</th>\n",
       "      <th>snow</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>10087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.248520</td>\n",
       "      <td>0.196350</td>\n",
       "      <td>0.013412</td>\n",
       "      <td>0.528641</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>10088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.410492</td>\n",
       "      <td>0.176392</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.405426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>10089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055969</td>\n",
       "      <td>0.259369</td>\n",
       "      <td>0.226807</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>0.426941</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>10090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.037643</td>\n",
       "      <td>0.517822</td>\n",
       "      <td>0.148590</td>\n",
       "      <td>0.285034</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>10091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026031</td>\n",
       "      <td>0.363190</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>0.397568</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id  no_data  clouds  artificial  cultivated  broadleaf  \\\n",
       "3436      10087      0.0     0.0    0.007431    0.248520   0.196350   \n",
       "3073      10088      0.0     0.0    0.004990    0.410492   0.176392   \n",
       "497       10089      0.0     0.0    0.055969    0.259369   0.226807   \n",
       "1319      10090      0.0     0.0    0.009201    0.037643   0.517822   \n",
       "2484      10091      0.0     0.0    0.026031    0.363190   0.188400   \n",
       "\n",
       "      coniferous  herbaceous   natural  snow     water  \n",
       "3436    0.013412    0.528641  0.000122   0.0  0.005524  \n",
       "3073    0.002701    0.405426  0.000000   0.0  0.000000  \n",
       "497     0.024384    0.426941  0.000015   0.0  0.006516  \n",
       "1319    0.148590    0.285034  0.001709   0.0  0.000000  \n",
       "2484    0.024353    0.397568  0.000229   0.0  0.000229  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.DataFrame.from_dict(sub_dict)\n",
    "df_sub = df_sub.sort_values(by='sample_id')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(),\"unet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_saved_model(model_name):\n",
    "    \"\"\"Loads the saved model\"\"\"\n",
    "    model = unet\n",
    "    model.load_state_dict(torch.load(model_name, map_location = device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model_loaded = loading_saved_model(\"unet.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2s",
   "language": "python",
   "name": "l2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
