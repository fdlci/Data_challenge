{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Essentials\n",
    "import time\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import os\n",
    "from tifffile import TiffFile\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "# Torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "# segmentation_models_pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "# Albumentations\n",
    "import albumentations as albu\n",
    "# Local \n",
    "from unet import UNet\n",
    "from LCD import LandCoverData\n",
    "from dataset import *\n",
    "from train import *\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom transforms\n",
    "\n",
    "The motivation behind redefining transforms is that we need to apply the same transform to both mask and image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCD = LandCoverData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set contains 14792 elements\n",
      "Validation set contains 3699 elements\n",
      "Test set contains 5043 elements\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "train_idx, val_idx = train_val_dataset(train_dir, val_split=0.2)\n",
    "train_set = ImageSegementationDataset(train_dir, path_index=train_idx, mode='train')\n",
    "val_set = ImageSegementationDataset(train_dir, path_index=val_idx, mode='valid')\n",
    "test_set = ImageSegementationDataset(test_dir, mode='test')\n",
    "\n",
    "print(\"Train set contains\", len(train_set), \"elements\")\n",
    "print(\"Validation set contains\", len(val_set), \"elements\")\n",
    "print(\"Test set contains\", len(test_set), \"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1849, 'valid': 463}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "epochs= 10\n",
    "lr= 0.001\n",
    "\n",
    "loader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "loader_valid = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "data_sizes = {\"train\": len(loader_train), \"valid\": len(loader_valid)}\n",
    "print(data_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = (y_pred_f * y_true_f).sum()\n",
    "    smooth = 0.0001\n",
    "    return 1 - (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "def change_shape(y_true, y_pred, numLabels):  \n",
    "\n",
    "    encoded_target = y_pred.data.clone().zero_()\n",
    "    encoded_target[...] = 0\n",
    "    encoded_target.scatter_(1, torch.tensor(y_true.unsqueeze(1), dtype=torch.int64), 1.)\n",
    "    encoded_target = Variable(encoded_target)\n",
    "    return encoded_target\n",
    "\n",
    "def dice_coef_multilabel(y_pred, y_true, numLabels):\n",
    "    dice=0\n",
    "    y_true = change_shape(y_true, y_pred, numLabels)\n",
    "    for index in range(numLabels):\n",
    "        dice += dice_coef(y_true[:,index,:,:], y_pred[:,index,:,:])\n",
    "    return dice/numLabels # taking average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIOU(label, pred, num_classes=10):\n",
    "    iou_list = list()\n",
    "    present_iou_list = list()\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    # Note: Following for loop goes from 0 to (num_classes-1)\n",
    "    # and ignore_index is num_classes, thus ignore_index is\n",
    "    # not considered in computation of IoU.\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = (pred == sem_class)\n",
    "        target_inds = (label == sem_class)\n",
    "        if target_inds.long().sum().item() == 0:\n",
    "            iou_now = float('nan')\n",
    "        else: \n",
    "            intersection_now = (pred_inds[target_inds]).long().sum().item()\n",
    "            union_now = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection_now\n",
    "            iou_now = float(intersection_now) / float(union_now)\n",
    "            present_iou_list.append(iou_now)\n",
    "        iou_list.append(iou_now)\n",
    "    return np.mean(present_iou_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_kl_divergence(y_true, y_pred):\n",
    "    class_distribution_true = np.apply_along_axis(np.bincount, axis=1, arr=y_true.flatten(1), minlength=LCD.N_CLASSES)\n",
    "    class_distribution_pred = np.apply_along_axis(np.bincount, axis=1, arr=y_pred.flatten(1), minlength=LCD.N_CLASSES)\n",
    "    # Normalize to sum to 1  \n",
    "    normalized_class_distribution_true = (class_distribution_true.T/class_distribution_true.sum(1)).T\n",
    "    normalized_class_distribution_pred = (class_distribution_pred.T/class_distribution_pred.sum(1)).T\n",
    "    # add a small constant for smoothness around 0\n",
    "    normalized_class_distribution_true += 1e-7\n",
    "    normalized_class_distribution_pred += 1e-7\n",
    "\n",
    "    score = np.mean(np.sum(normalized_class_distribution_true * np.log(normalized_class_distribution_true / normalized_class_distribution_pred), 1))\n",
    "    try:\n",
    "        assert np.isfinite(score)\n",
    "    except AssertionError as e:\n",
    "        raise ValueError('score is NaN or infinite') from e\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight():\n",
    "    weights = np.zeros((LCD.N_CLASSES,))\n",
    "    num_ign_classes = len(LCD.IGNORED_CLASSES_IDX)\n",
    "    weights[num_ign_classes:] = (1 / LCD.TRAIN_CLASS_COUNTS[2:])* LCD.TRAIN_CLASS_COUNTS[2:].sum() / (LCD.N_CLASSES-2)\n",
    "    weights[LCD.IGNORED_CLASSES_IDX] = 0.\n",
    "\n",
    "    class_weights = torch.FloatTensor(weights)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, valid_loader, data_sizes, epochs, optimizer, scheduler, title):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device\", device)\n",
    "    model.to(device)\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    num_workers = 1\n",
    "\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    loaders = {\"train\": train_loader, \"valid\": valid_loader}\n",
    "    print(data_sizes)\n",
    "    step = 0\n",
    "\n",
    "    #class_weights = class_weight().to(device)\n",
    "    #criterion = nn.CrossEntropyLoss(class_weights)\n",
    "    criterion = dice_coef_multilabel\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_iou = 0\n",
    "            running_kl_div = 0\n",
    "\n",
    "            for image, mask in tqdm(loaders[phase]):\n",
    "                image = image.to(device)\n",
    "                mask = mask.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "\n",
    "                    output = model(image)\n",
    "                    # print(output)\n",
    "                    _, preds = torch.max(output, 1)\n",
    "\n",
    "                    #loss = criterion(output, torch.tensor(mask, dtype=torch.long, device=device).squeeze())\n",
    "                    # print(preds.size())\n",
    "                    # print(torch.argmax(output, axis=1).shape)\n",
    "                    loss = criterion(output, mask.squeeze(), LCD.N_CLASSES)\n",
    "                \n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                # running_corrects += torch.sum(iou_pytorch(output, mask))\n",
    "                running_iou += mIOU(mask, preds)\n",
    "                running_kl_div += epsilon_kl_divergence(mask.cpu(), preds.cpu())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss/data_sizes[phase]\n",
    "            epoch_iou = running_iou/data_sizes[phase]\n",
    "            epoch_kl = running_kl_div/data_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                training_loss.append(epoch_loss)\n",
    "            else:\n",
    "                validation_loss.append(epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:.4f} IoU: {:.4f} KL_div: {:.4f}'.format(phase, epoch_loss, epoch_iou, epoch_kl))\n",
    "            \n",
    "            if phase == 'valid' and epoch_iou > best_acc:\n",
    "                best_acc = epoch_iou\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            \n",
    "    # Plotting the validation loss and training loss\n",
    "    print('validation loss: ' + str(validation_loss))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # plot the training and validation loss\n",
    "    plt.figure()\n",
    "    plt.plot(training_loss, 'b', label='Training Loss')\n",
    "    plt.plot(validation_loss, 'r', label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show() #Change title for every model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_dir, model, epochs):\n",
    "    \n",
    "    # class_weights = class_weight()\n",
    "\n",
    "    # Optimizing all parameters\n",
    "    optimizer_ft = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.5)\n",
    "\n",
    "    # Training the model\n",
    "    title = 'Variations of the training and validation loss SGD'\n",
    "    model_ft = training(model, loader_train, loader_valid, data_sizes, epochs, optimizer_ft, exp_lr_scheduler, title)\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_pre_trained = smp.Unet(encoder_name='timm-efficientnet-b3',in_channels=4, classes=10, activation='softmax')\n",
    "unet_pre_trained.load_state_dict(torch.load(\"unet_timm-efficientnet-b3_20_epochs.pt\", map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda:0\n",
      "{'train': 1849, 'valid': 463}\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a470d7cb60514e6c9d190659f2e48669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JaggBow\\anaconda3\\envs\\l2s\\lib\\site-packages\\segmentation_models_pytorch\\base\\modules.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n",
      "<ipython-input-10-78a706cb2fa7>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encoded_target.scatter_(1, torch.tensor(y_true.unsqueeze(1), dtype=torch.int64), 1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5050 IoU: 0.5670 KL_div: 0.0458\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2db20a9c544e43b5f716553d9639ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.5039 IoU: 0.5686 KL_div: 0.0446\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6625b6e475ad47daa60f51c8ce910e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5032 IoU: 0.5682 KL_div: 0.0457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29fb2b01ef6413a9cb78d60ac811921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.5060 IoU: 0.5643 KL_div: 0.0510\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6913632f298e428492b915ce63b228c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5016 IoU: 0.5713 KL_div: 0.0428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55364d5f74a4299831c1cc10963db96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.5095 IoU: 0.5593 KL_div: 0.0682\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14f0a2d31724b35964e067ff633c7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3416 IoU: 0.5658 KL_div: 0.0469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4371c4f814495b8d996a8b8f033a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2304 IoU: 0.5699 KL_div: 0.0407\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a091626511c4321b48feaefd134ec6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2275 IoU: 0.5719 KL_div: 0.0418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824f2991ad7d4fa9bf130c0e93e36586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2373 IoU: 0.5620 KL_div: 0.0518\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767d185de77c4280ab18ab59e3892e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2260 IoU: 0.5742 KL_div: 0.0398\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8533361e651480986035e629948f7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2331 IoU: 0.5633 KL_div: 0.0567\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3703f85e8e49619ab13bbde8bd18c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2251 IoU: 0.5763 KL_div: 0.0393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d93a8688c9b43cca76c474e6e7bfe3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2312 IoU: 0.5699 KL_div: 0.0357\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76a52ef38f94f498126211cc49343f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2221 IoU: 0.5804 KL_div: 0.0362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e113f615b104f5d866218867678447f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2276 IoU: 0.5755 KL_div: 0.0352\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3086b568374333928680bf6aa219b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2222 IoU: 0.5804 KL_div: 0.0365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d2d3b3db864378bcaecfcb4fa50a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2245 IoU: 0.5805 KL_div: 0.0360\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d0fa7b809d46beb347b22f6bfdae53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1849 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2208 IoU: 0.5818 KL_div: 0.0366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0798d691f4403895d3bff58d04e90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2288 IoU: 0.5749 KL_div: 0.0405\n",
      "validation loss: [0.5039185060280703, 0.5060405691936773, 0.5095220787478832, 0.23037145264269723, 0.23733271994742666, 0.23305901246181573, 0.23118316390215707, 0.22758903882222867, 0.22449039300947932, 0.22881265188975675]\n",
      "Training complete in 94m 7s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (conv_stem): Conv2d(4, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): Swish()\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "          (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "        (1): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "          (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "          (bn2): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "          (bn2): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): Swish()\n",
       "          (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "          (bn2): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Swish()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): Swish()\n",
       "            (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): Swish()\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(520, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(304, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(104, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Softmax(dim=None)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model('dataset/train', unet_pre_trained, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec084a0889b415f92dc66e295bdca73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation IoU 0.5804167071280101 Validation KL divergence 0.0359525565287476\n"
     ]
    }
   ],
   "source": [
    "running_iou = 0\n",
    "running_kl_div = 0\n",
    "unet_pre_trained.eval()\n",
    "for image, mask in tqdm(loader_valid):\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = unet_pre_trained(image)\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        running_iou += mIOU(mask, preds)\n",
    "        running_kl_div += epsilon_kl_divergence(mask.cpu(), preds.cpu())\n",
    "\n",
    "\n",
    "epoch_iou = running_iou/len(loader_valid)\n",
    "epoch_kl = running_kl_div/len(loader_valid)\n",
    "\n",
    "print('Validation IoU', epoch_iou, \"Validation KL divergence\", epoch_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(unet_pre_trained.state_dict(),\"unet_timm-efficientnet-b3_30_epochs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_distribution(y):\n",
    "    class_distribution = np.apply_along_axis(np.bincount, axis=1, arr=y.flatten(1), minlength=LCD.N_CLASSES)\n",
    "    # Normalize to sum to 1  \n",
    "    return (class_distribution.T/class_distribution.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_data',\n",
       " 'clouds',\n",
       " 'artificial',\n",
       " 'cultivated',\n",
       " 'broadleaf',\n",
       " 'coniferous',\n",
       " 'herbaceous',\n",
       " 'natural',\n",
       " 'snow',\n",
       " 'water']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCD.CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee934a0f25814067a763f5d3782e2dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JaggBow\\anaconda3\\envs\\l2s\\lib\\site-packages\\segmentation_models_pytorch\\base\\modules.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n"
     ]
    }
   ],
   "source": [
    "sub_dict = {\"sample_id\":[], \"no_data\":[],\"clouds\":[],\"artificial\":[],\"cultivated\":[],\"broadleaf\":[],\"coniferous\":[],\"herbaceous\":[],\"natural\":[],\"snow\":[],\"water\":[]}\n",
    "for image, path in tqdm(loader_test):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = unet_pre_trained(image)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        class_dis = batch_distribution(preds.cpu())\n",
    "        sub_dict[\"sample_id\"] += [int(p.split('.')[0]) for p in path]\n",
    "        for key in LCD.CLASSES:\n",
    "            sub_dict[key] += class_dis[:,LCD.CLASSES.index(key)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>no_data</th>\n",
       "      <th>clouds</th>\n",
       "      <th>artificial</th>\n",
       "      <th>cultivated</th>\n",
       "      <th>broadleaf</th>\n",
       "      <th>coniferous</th>\n",
       "      <th>herbaceous</th>\n",
       "      <th>natural</th>\n",
       "      <th>snow</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>10087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.235489</td>\n",
       "      <td>0.198532</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.543549</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>10088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.395966</td>\n",
       "      <td>0.172546</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.422394</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>10089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050873</td>\n",
       "      <td>0.236862</td>\n",
       "      <td>0.218674</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>0.461685</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>10090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.031128</td>\n",
       "      <td>0.511948</td>\n",
       "      <td>0.141098</td>\n",
       "      <td>0.299408</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4339</th>\n",
       "      <td>10091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.177231</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>0.378784</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id  no_data  clouds  artificial  cultivated  broadleaf  \\\n",
       "982       10087      0.0     0.0    0.006195    0.235489   0.198532   \n",
       "1585      10088      0.0     0.0    0.004242    0.395966   0.172546   \n",
       "4702      10089      0.0     0.0    0.050873    0.236862   0.218674   \n",
       "4922      10090      0.0     0.0    0.015839    0.031128   0.511948   \n",
       "4339      10091      0.0     0.0    0.025101    0.392700   0.177231   \n",
       "\n",
       "      coniferous  herbaceous   natural  snow     water  \n",
       "982     0.010422    0.543549  0.000351   0.0  0.005463  \n",
       "1585    0.004623    0.422394  0.000229   0.0  0.000000  \n",
       "4702    0.024994    0.461685  0.000443   0.0  0.006470  \n",
       "4922    0.141098    0.299408  0.000580   0.0  0.000000  \n",
       "4339    0.025681    0.378784  0.000275   0.0  0.000229  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.DataFrame.from_dict(sub_dict)\n",
    "df_sub = df_sub.sort_values(by='sample_id')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(),\"unet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_saved_model(model_name):\n",
    "    \"\"\"Loads the saved model\"\"\"\n",
    "    model = unet\n",
    "    model.load_state_dict(torch.load(model_name, map_location = device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model_loaded = loading_saved_model(\"unet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_ids(test_images):\n",
    "    id_list = []\n",
    "    for test_image in os.listdir(os.path.join(test_images,'images')):\n",
    "        id_im = int(re.findall(r'\\d+', test_image)[0])\n",
    "        id_list.append(id_im)\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['no_data', 'clouds', 'artificial', 'cultivated', 'broadleaf', 'coniferous', 'herbaceous', 'natural', 'snow', 'water']\n",
    "\n",
    "ids_test = np.arange(10)\n",
    "\n",
    "def compute_class_counts(masks, n_classes):\n",
    "\n",
    "    dist = np.zeros((masks.size(0), n_classes))\n",
    "\n",
    "    for i, mask in enumerate(masks):\n",
    "        arr = mask.cpu().numpy()\n",
    "        count = np.bincount(arr.ravel(), minlength=n_classes)\n",
    "        count[0], count[1] = 0, 0\n",
    "        dist[i] = count/np.sum(count)\n",
    "    return dist\n",
    "\n",
    "def getting_pixel_distribution(model, test_loader, test_size, ids):\n",
    "\n",
    "    indx_test = np.arange(10087,10087+test_size, dtype=np.int32).reshape(-1,1)\n",
    "    all_dist = np.zeros((test_size, LCD.N_CLASSES))\n",
    "    previous = 0\n",
    "\n",
    "    for counter, images in enumerate(tqdm(test_loader)):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        distributions = compute_class_counts(preds, LCD.N_CLASSES)\n",
    "        all_dist[previous:previous+images.size(0)] = distributions\n",
    "        previous = previous+images.size(0)\n",
    "\n",
    "    df = pd.DataFrame(all_dist, columns=column_names)\n",
    "    df.insert(0, 'Sample_id', ids)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'dataset/test'\n",
    "test_set = ImageSegementationDataset(test_dir, mode='test')\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "test_size = len(test_set)\n",
    "ids = sorted(get_ids(test_dir))\n",
    "\n",
    "model_loaded.eval()\n",
    "df = getting_pixel_distribution(model_loaded, test_loader, test_size, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_from_pandas_csv(df):\n",
    "    df.to_csv(r'results.csv', index = False)\n",
    "\n",
    "create_from_pandas_csv(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2s",
   "language": "python",
   "name": "l2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
